{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c31c8a-df8e-43ba-8b5c-1b239bd7b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb81fbb-06f9-4844-a45c-8083ba23f7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acf', 'chembl', 'molnet']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench_result = Path(\"benchmark_model_consensus\")\n",
    "os.listdir(bench_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e475d6c-32d3-4c72-a9ba-4946758ebf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_folder = os.path.join(bench_result, \"chembl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9254c2d1-cd94-434a-b5e8-9c396a8a74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_true, y_pred, metric='mae'):\n",
    "    if metric == 'mae':\n",
    "        acc = mean_absolute_error(y_true, y_pred)\n",
    "    elif metric == 'r2':\n",
    "        acc = r2_score(y_true, y_pred)\n",
    "    elif metric == 'rmse':\n",
    "        acc = root_mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c6d0bd-38da-4c29-be38-3979119afa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"r2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07282992-639c-4df4-89ad-f9a7281c5bba",
   "metadata": {},
   "source": [
    "### 1. Mean/median prediction accuracy\n",
    "\n",
    "### TODO: dirty code -> clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91d7adbc-bab2-4650-a737-6d14fc78bd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Genetic</th>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Systematic</th>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best</th>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stack_test_RandomForestRegressor()</th>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stack_test_KNeighborsRegressor()</th>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stack_test_Ridge()</th>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stack_test_LinearRegression()</th>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stack_test_SVR()</th>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stack_test_MLPRegressor()</th>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0\n",
       "Genetic                             0.67\n",
       "Systematic                          0.65\n",
       "Best                                0.65\n",
       "Stack_test_RandomForestRegressor()  0.63\n",
       "Stack_test_KNeighborsRegressor()    0.52\n",
       "Stack_test_Ridge()                  0.50\n",
       "Stack_test_LinearRegression()       0.49\n",
       "Random                              0.47\n",
       "Stack_test_SVR()                    0.40\n",
       "All                                 0.37\n",
       "Stack_test_MLPRegressor()           0.29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for bench_dataset in os.listdir(bench_folder):\n",
    "\n",
    "    # read predictions\n",
    "    train_df = pd.read_csv(os.path.join(bench_folder, bench_dataset, \"train.csv\"))\n",
    "    test_df = pd.read_csv(os.path.join(bench_folder, bench_dataset, \"test.csv\"))\n",
    "    \n",
    "    # calc accuracy metric for each consensus/stacking method for test set predictions\n",
    "    result_test = test_df.drop(columns='Y_TRUE').apply(lambda col: calc_accuracy(test_df['Y_TRUE'], col, metric=metric))\n",
    "\n",
    "    # get rid of scientific nitation like -1.422665e+09 for stable mean calcualtion\n",
    "    # ATTENTION! if for example r2 = -12435t5.2 it will be converted to 0 for the method -> it is nit completely correct\n",
    "    if metric == \"r2\": # conditions for TODO other metrics (ame, rmse)\n",
    "        result_test = result_test.where(result_test > 10 ** -3, other=0)\n",
    "    \n",
    "    tmp.append(result_test)\n",
    "\n",
    "# calc mean accuracy #TODO choose mean or median\n",
    "result_mean = sum(tmp) / len(tmp)\n",
    "result_mean = result_mean.sort_values(ascending=False).to_frame()\n",
    "result_mean.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d86dcb-82c6-4837-b22f-92e11759b449",
   "metadata": {},
   "source": [
    "### 2. Prediction accuracy boxplot\n",
    "\n",
    "### TODO: implement the boxplot of accuracy distribution over datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158a49d6-8e81-42b1-8dca-1635951167f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db95359-b8a6-442c-ae74-081ee8bc85b9",
   "metadata": {},
   "source": [
    "### 3. Top-N statistics\n",
    "\n",
    "### TODO: implement the choice of N (Top-1, Top-2, Top-5, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1709c7c-a552-428c-962f-f8d06da4fa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Genetic': 141,\n",
       "         'Best': 29,\n",
       "         'Stack_test_RandomForestRegressor()': 21,\n",
       "         'Stack_test_Ridge()': 6,\n",
       "         'Stack_test_LinearRegression()': 2,\n",
       "         'Stack_test_MLPRegressor()': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_1 = []\n",
    "for metrics_df in tmp: # tmp comes from step 1 -> not OK, may be tmp (the list of metrics for each dataset) should be shared across the notebook\n",
    "    min_i = metrics_df.argmin()\n",
    "    max_i = metrics_df.argmax()\n",
    "    #\n",
    "    top_1.append(metrics_df.index[max_i]) # max for r2, should be min for mae, rmse -> implement the choice\n",
    "#\n",
    "Counter(top_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df69fed6-a3b9-44a8-85fc-a0e8df589e6e",
   "metadata": {},
   "source": [
    "### 4. Pair accuracy comparison\n",
    "### TODO: this is a metric from JCIM paper on MIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f012a4be-655b-4265-97f2-9d5b3a74f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method_1 vs method_2 - calculate the number of wins (accuracy_1 > accuracy_2)\n",
    "# to be implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca11b0-617a-4501-add5-67864f1f4e24",
   "metadata": {},
   "source": [
    "### 5. CI Diagram from JCIM paper on MIL\n",
    "### TODO: DZ -> I will find the code for building this diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "586eea5c-bd08-4c93-8971-7afe22c6cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f435d90-2b42-45c3-8bf1-97a3b1c3a358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miprop",
   "language": "python",
   "name": "miprop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
